
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Ищем темы в Игре Престолов - DataDeep Evil Twin</title>
  <meta name="author" content="Команда datadeep.ru">

  
  <meta name="description" content="Основы тематического моделирования на примере текста книг серии "Песнь Льда и Пламени"">
  <meta name="keywords" content="visualization">

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://datadeep.ru/blog/2015/09/13/zim-blizk">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="DataDeep Evil Twin" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  

</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">DataDeep Evil Twin</a></h1>
  
    <h2>Sapere aude</h2>
  
</hgroup>

</header>
  <nav role="navigation">
  
<form action="https://www.google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:datadeep.ru" />
    <input class="search" type="text" name="q" results="0" placeholder="Поиск"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Блог</a></li>
  <li><a href="/blog/archives">Архив блога</a></li>
  <li><a href="/about_blog">О блоге</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div>
<article class="hentry" role="article">
  
  <header>
    
      <h1 class="entry-title">Ищем темы в Игре Престолов</h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2015-09-13T14:54:20+03:00'><span class='date'>13/09/2015</span> <span class='time'>14:54</span></time>
        
      </p>
    
  </header>


<div class="entry-content"><p>Когда мы имеем дело с большим количеством текстовых документов, первое что нас интересует — о чем эти документы: есть ли между ними что-то общее, о чем каждый из документов, о чем они в целом? Попробуем ответить на эти вопросы воспользовавшись инструментарием науки о данных. Да не просто так, а на примере серии книг “Песнь Льда и Пламени”, известной также как “Игра Престолов”.</p>

<p><img src="/images/2015-09_TopicModelling_GameOfThrones/GameOfThrones_tag_cloud.jpg" width="768" height="576" title="КДПВ" /></p>

<!-- more -->

<p>Одно из основных понятий, которое может помочь отметить на заданные вопросы —  <em>тема</em>. Тема — это то, о чем говориться в тексте, например, объект его обсуждения. Разумеется, любой может определить основную тему текста, прочитав его. Однако, есть несколько причин поступить иначе. Во-первых, этот процесс достаточно трудоемкий, особенно если учесть потенциально большие коллекции документов (например, весь интернет). Во-вторых, этот подход субъективный, а хотелось бы получить объективную (а еще лучше, численную) характеристику тематики текста. Наконец, этот блог не о чтении, а об анализе данных. И именно путем анализа данных мы и планируем пойти.</p>

<p>Для ответа на наши вопросы мы воспользуемся таким подходом, как <em>тематическое моделирование</em>. Тематическое моделирование — это подраздел машинного обучения, заключающийся в построении <em>тематической модели</em> по заданному текстовому корпусу. В свою очередь, тематическая модель — это статистическая модель, которая моделирует взаимосвязь наблюдамемых переменных: слов и документов и ненаблюдаемых переменных — тем, отвечая тем самым на два основных вопроса:</p>

<ol>
  <li>Какие слова образуют каждую из тем?</li>
  <li>К каким темам относится каждый из документов?</li>
</ol>

<p>В этой статье мы разберемся в алгоритме LSA — одном из базовых алгоритмов тематического моделирование, а реализуем его на языке Python, а главное — применим его на корпусе, составленном из книг серии “Песнь Льда и Пламени”. Соответственно, статья состоит из трех частей: теории, практики и обсуждения результатов. Первая часть может вызвать приступ “T.L.D.R.”, поэтому если вы знакомы с основами тематического моделирования или же в них не заинтересованы, то можете сразу переходить ко второй части. Если же интересно узнать лишь что получилось — смело прокручивайте до третьей части.</p>

<h1 id="section">Часть 1. Теория</h1>

<p>В это части мы сначала опишем несколько алгоритмов, а затем покажем как объединив их вместе можно получить алгоритм тематического моделирования LSA.</p>

<p>Итак, определившись с тем что мы хотим получить (тематическую модель), остается понять, как же это сделать. Сразу скажу, без математики не обойтись. К сожалению, математике не знакомы понятия “текст”, “документ”, “слово”, “тема” и т.п. Зато, ей хорошо понятен язык чисел и векторов. И именно на язык векторов нам и предстоит перейти для решения нашей задачи. Для этого мы воспользуемся так называемой <em>векторной моделью</em> текста — “переведем” наш корпус с прикладного языка слов и документов на абстрактный язык линейной алгебры.</p>

<h2 id="section-1">Векторная модель</h2>
<p>Векторная модель — модель представления текстовых документов в виде числовых векторов, где каждое размерность вектора-документа соответствует какому-либо слову. Рассмотрим построение этой модели.</p>

<p>На входе мы имеем коллекцию из <script type="math/tex">N</script> документов. Пронумеруем их числами от 1 до <script type="math/tex">N</script>, так что индексом <script type="math/tex">d \in \{1..N\}</script> обозначается <script type="math/tex">d</script>-й элемент коллекции. Далее, рассмотрим словарь слов — все уникальные слова, встречающиеся в наших документах. Допустим, таких слов <script type="math/tex">M</script> штук и пронумеруем их от 1 до <script type="math/tex">M</script> индексом <script type="math/tex">w</script>. Теперь, посчитаем сколько раз каждое слово <script type="math/tex">w=1..M</script> входит входит в каждый документ <script type="math/tex">d=1..N</script> и обозначим это число <script type="math/tex">n_{d,w}</script>. Из этих чисел сформируем матрицу <script type="math/tex">\mathbf{X} = (n_{d,w})_{d,w}</script> — <a href="https://en.wikipedia.org/wiki/Document-term_matrix">матрицу частот слов в документах</a>. Строки этой матрицы соответствуют документам, а столбцы — словам. Скорее всего, эта матрица будет <em>разряженной</em> — большая часть ее элементов будет равна нулю (ведь каждый документ содержит лишь небольшую долю всех слов).</p>

<p>Перевод окончен! Теперь наш текстовый корпус представлен в виде матрицы <script type="math/tex">\mathbf{X}</script>. 
В результате получится матрица выглядящая примерно следующим образом.</p>

<p><img src="/images/2015-09_TopicModelling_GameOfThrones/GameOfThrones_X_matrix_vis.svg" width="384" height="288" title="Матрица документ-слово" /></p>

<p>Стоит заметить, что подобная модель под собой имеет два основных предположения.</p>

<ul>
  <li>Порядок документов в коллекции не имеет значения.</li>
  <li>Порядок слов в документе не имеет значения (т.н. “мешок слов” или “bag of words”).</li>
</ul>

<p>Если первое предположение вполне естественно, то второе может показаться неоднозначным. Казалось, даже такая мелочь, как запятая в предложении “казнить нельзя, помиловать” полностью меняет его смысл, что уж говорить о порядке слов даже не в одном предложении, а в нескольких абзацах. Несмотря на это резонное замечание, модель “мешка слов” — одна из наиболее широко используемых и хорошо зарекомендовавшая себя на практике. Тем более это верно для такой задачи, как определение темы. Действительно, как не расставляй слова и знаки препинания в предложении “казнить, нельзя помиловать”, легко понять что речь идет о казни (“казнить” же или “помиловать” — детали).</p>

<h2 id="section-2">Стемминг</h2>
<p>Далее развивая мысль о значимости тех или иных деталей для определения тематики текста, можно заметить, что слово может встречаться в тексте в различных формах: с различными окончаниями и приставками, — но с единым смыслом. Например, неважно какую форму слова мы встретили в тексте: “казнить”, “казнят”, “казнен”, “казню”, “казнишь”, “казни” — все они относятся к теме “казнь”. Именно на нахождение <a href="https://ru.wikipedia.org/wiki/%D0%9E%D1%81%D0%BD%D0%BE%D0%B2%D0%B0_%D1%81%D0%BB%D0%BE%D0%B2%D0%B0">основы слова</a> по той или иной заданной его форме и направлен такой инструмент, как <em>стемминг</em>. 
Здесь мы не будем разъяснять, какие бывают алгоритма стемминга (а их довольно много) и как они работают. Если возникнет интерес, можно начать со 
<a href="https://ru.wikipedia.org/wiki/%D0%A1%D1%82%D0%B5%D0%BC%D0%BC%D0%B8%D0%BD%D0%B3">статьи в википедии</a>. Скажем только, что в дальнейшем мы будем использовать <a href="http://snowball.tartarus.org/">стеммер Snowball</a>, а точнее <a href="http://www.nltk.org/_modules/nltk/stem/snowball.html">его реализацию в NLTK</a>.</p>

<p>Имея в руках стеммер, можно использовать его для преобразования каждого слова каждого документа в его нормальную форму. Тем самым мы, во-первых, значительно уменьшим общее число слов, а следовательно и вычислительную трудоемкость, а во-вторых, упростим дальнейшую интерпретацию результатов.</p>

<h2 id="tf-idf">TF-IDF</h2>
<p>TF-IDF — (Term Frequency - Inverse Document Frequency) методика оценки важности слова в документе. Она опирается на два основных предположения</p>

<ol>
  <li>Частота появления слова в документе пропорциональна его важности в этом документе.</li>
  <li>Число документов, в котором встречается слово обратно пропорционально его важности.</li>
</ol>

<p>Первое предположение вполне логично, а если поразмыслить то и с обоснованием второго не возникнет проблем: возьмем, например, “и” или “а” — они наверняка встретятся в большинстве документов, но на вряд ли привносят что-то в их тематику. Другой пример: возьмем текст новостей, посвященных гражданину Н-му. Естественно, 99.9% из них будут содержать его фамилию в той или иной форме, которая в то же время, будет совершенно бесполезна для определение их темы (в контексте общей темы, посвященной этому гражданину).</p>

<p>Эти два предположения TFIDF учитывает с помощью функций  <script type="math/tex">\mathrm{tf}</script> и <script type="math/tex">\mathrm{idf}</script> соответственно. Задаются они следующим образом</p>

<ul>
  <li><script type="math/tex">\mathrm{tf}(w, d) = n_{w, d}</script> — число вхождений слова <script type="math/tex">w</script> в документ <script type="math/tex">d</script>;</li>
  <li><script type="math/tex">\mathrm{idf}(w) = \log \frac{N}{\lvert \{d \; : \; n_{w, d} > 0\} \rvert }</script> — логарифм обратной доли документов, содержащих слово <script type="math/tex">w</script>.</li>
</ul>

<p>Итоговая же оценка важности слова <script type="math/tex">w</script> для документа <script type="math/tex">d</script> описывается функцией <script type="math/tex">\mathrm{tfidf}</script>:</p>

<script type="math/tex; mode=display">\mathrm{tfidf}(w, d) = \mathrm{tf}(w, d) * \mathrm{idf}(w)</script>

<p>Таким образом, меняя <script type="math/tex">\mathbf{X} = (n_{d,w})_{d,w}</script> на матрицу <script type="math/tex">X_{tfidf} = (\mathrm{tfidf}(w, d))_{d, w}</script>, мы понижаем важность слов, встречающихся в большинстве документов и повышаем ее у слов встречающихся в относительно небольшом подмножестве документов.</p>

<h2 id="section-3">Сингулярное разложение</h2>

<p>Потихоньку мы подбираемся к самому интересному. Как же найти ответы на наши вопросы касательно тем?
Напомним, на какие вопросы должна ответить искомая тематическая модель коллекции документов.</p>

<ol>
  <li>Какие слова образуют каждую из тем?</li>
  <li>К каким темам относится каждый из документов?</li>
</ol>

<p>Наша задача — численно ответить на эти вопросы на том же языке, на котором описана матрица документов-слов <script type="math/tex">\mathbf{X}</script>.</p>

<p>Рассмотрим конкретную тему <script type="math/tex">t</script> и ответы на эти вопросы в векторном виде:</p>

<ol>
  <li>Вектор <script type="math/tex">u_t \in \mathrm{R}^{N }</script>, <script type="math/tex">d</script>-й элемент которого <script type="math/tex">u_t^{(d)}</script> символизирует близость темы <script type="math/tex">t</script> документу <script type="math/tex">d</script>.</li>
  <li>Вектор <script type="math/tex">v_t \in \mathrm{R}^{M }</script>, <script type="math/tex">w</script>-й элемент которого <script type="math/tex">v_t^{(w)}</script> символизирует важность слова <script type="math/tex">w</script> для темы <script type="math/tex">t</script>.</li>
</ol>

<p>Заметим, что если слово <script type="math/tex">w</script> важно для темы <script type="math/tex">t</script> (<script type="math/tex">v_t^{(w)}</script> велико), а тема <script type="math/tex">t</script> близка документу <script type="math/tex">d</script> (<script type="math/tex">u_t^{(d)}</script> велико), то велико будет и их произведение: <script type="math/tex">u_t^{(d)} v_t^{(w)}</script>. Если же тема <script type="math/tex">t</script> близка документу <script type="math/tex">d</script>, а слово <script type="math/tex">w</script>, напротив, не играет роли в теме <script type="math/tex">t</script> (<script type="math/tex">v_t^{(w)} \sim 0</script>), то и их произведение будет близко к нулю: <script type="math/tex">u_t^{(d)} v_t^{(w)}\sim 0</script>.   Более того, если перемножить два этих вектора, то получившаяся матрица <script type="math/tex">X_t = u_t v_t^T</script> будет ни чем иным как корпус с единственной темой — темой <script type="math/tex">t</script>.</p>

<p>Развивая эту идею, задачу построения тематической модели можно сформулировать следующим образом: найти комбинацию тем $t=1..K$ и соответствующих им векторов <script type="math/tex">u_t</script> и <script type="math/tex">v_t</script>, таких что их комбинация наилучшим образом описывает исходный корпус <script type="math/tex">\mathbf{X}</script>. “Наилучшим образом” будем понимать в смысле наименьшего квадратичного отклонения:</p>

<script type="math/tex; mode=display">\lvert\lvert X - \sum\limits_{t=1}^K u_t v_t^\top \rvert\rvert_2 \longrightarrow \min\limits_{\{u_t, v_t\}_{t=1}^K}.</script>

<p>Здесь на сцену выходит <em>сингулярное разложение</em> (<em>singular value decomposition</em>, <em>SVD</em>), решающее схожую задачу. Оно заключается в представлении вещественной матрицы <script type="math/tex">X \in \mathrm{R}^{N\times M}</script>, <script type="math/tex">N > M</script> в виде:</p>

<script type="math/tex; mode=display">X = U S V^\top = \sum_{t=1}^{M} s_t u_t v_t^\top,</script>

<p>где <script type="math/tex">U \in \mathrm{R}^{N\times M}</script>, <script type="math/tex">V \in \mathrm{R}^{M\times M}</script> — ортогональные матрицы, состоящие из левых (<script type="math/tex">u_t</script>) и правых (<script type="math/tex">v_t</script>) сингулярных векторов, а <script type="math/tex">S \in \mathrm{R}^{M\times M}</script> — диагональная матрица, на главной диагонали которой находятся сингулярные числа (<script type="math/tex">s_k</script>).</p>

<p>Для наглядности мы проиллюстрировали неполное сингулярное разложение матрицы документ-слово (крестиками обозначены ненулевые значения).</p>

<p><img src="/images/2015-09_TopicModelling_GameOfThrones/GameOfThrones_SVD_vis.svg" width="768" height="576" title="SVD матрицы документ-слово" /></p>

<p>Сингулярное разложение — одно из важнейших матричных разложений, применяемая во множестве как теоретических, так и практических областей: нахождении псевдообратной матрицы, решении линейных уравнений, снижении размерности, анализе временных рядов, рекомендательных системах и др. В качестве отправной точки можно обратится к <a href="https://ru.wikipedia.org/wiki/%D0%A1%D0%B8%D0%BD%D0%B3%D1%83%D0%BB%D1%8F%D1%80%D0%BD%D0%BE%D0%B5_%D1%80%D0%B0%D0%B7%D0%BB%D0%BE%D0%B6%D0%B5%D0%BD%D0%B8%D0%B5">википедии</a> или довольно наглядной статье на <a href="http://www.ams.org/samplings/feature-column/fcarc-svd">ams.org</a>.</p>

<p>SVD обладает множеством полезных слов, в контексте нашей задачи определения тем в корпусе нам интересны следующие:</p>

<ol>
  <li>Длинна правых сингулярных векторов равна единице: <script type="math/tex">v_t = 1</script> — это означает, что все вектора тем (<script type="math/tex">v_t</script>) лежат на единичной окружности в пространстве слов, тем самым находясь в едином масштабе, и все что их отличает друг от друга — это “угол поворота” — то какие слова для них более важные, а какие менее;</li>
  <li>Длинна левых сингулярных векторов равна единице: <script type="math/tex">u_t = 1</script> — вектора документов (<script type="math/tex">u_t</script>) лежат на единичной окружности в пространстве тем, аналогично находясь в едином масштабе, и их отличие заключается в пропорциях тех или иных тем;</li>
  <li>Все вектора <script type="math/tex">\{v_t\}</script> ортогональны друг другу — исключена возможность того, что все темы будут друг на друга похожи — в пространстве слов они ортогональны друг другу;</li>
  <li>Сингулярные числа <script type="math/tex">s_t</script> расположены на диагонали матрицы <script type="math/tex">S</script> по убыванию — сперва идут темы обладающие наибольшим вкладом в коллекцию;</li>
  <li>Сингулярные вектора определены с точность до знака: одновременно домножив <script type="math/tex">u_t</script> и $$v_t$ на -1 ничего не изменится — это значит, что у каждой темы есть, фактически два полюса: один описывается словами с наибольшим положительным весом, а другой — с наибольшим отрицательным;</li>
  <li>Если рассмотреть <em>сокращенное сингулярное разложение</em> (<em>truncated SVD</em>): <script type="math/tex">X_K = \sum_{t=1}^{K} s_t u_t v_t^\top</script>, то это будет *наилучшим приближением матрицы <script type="math/tex">X</script> ранга <script type="math/tex">K</script> (в терминах <script type="math/tex">\lvert\lvert.\rvert\rvert_2</script> нормы). Это означает, что любой другой набор из <script type="math/tex">K</script> тем, представленный в виде троек <script type="math/tex">\{u_t, s_t, v_t\}_1^K</script> будет хуже описывать наш исходный корпус.</li>
</ol>

<p>Довольно-таки неплохо! Учитывая, что это достается нам совершенно бесплатно :)</p>

<p>Подытожим. Имея матрицу <script type="math/tex">X</script>, все что нам нужно сделать для получения его тематической модели — это выбрать число <script type="math/tex">% <![CDATA[
K < N, M %]]></script> и воспользоваться SVD:</p>

<script type="math/tex; mode=display">U_K, S_K, V^\top_K = \mathrm{svd}(X, K)</script>

<p>и тогда каждую тройку <script type="math/tex">u_k, s_k, v_k</script> можно будет интерпретировать следующим образом:</p>

<ul>
  <li><script type="math/tex">u_t \in \mathrm{R}^{N}</script> — вектор соответствия темы <script type="math/tex">t</script> каждому из документов <script type="math/tex">d=1..N</script>, чем больше <script type="math/tex">u_t^{(d)}</script> — тем ближе документ <script type="math/tex">d</script> к теме <script type="math/tex">t</script>;</li>
  <li><script type="math/tex">v_t \in \mathrm{R}^{M}</script> — вектор соответствия слов <script type="math/tex">w=1..M</script> теме <script type="math/tex">t</script>, чем больше <script type="math/tex">v_t^{(w)}</script> — тем важнее слово <script type="math/tex">w</script> в теме <script type="math/tex">t</script>;</li>
  <li><script type="math/tex">s_t \in \mathrm{R}</script> — относительный вес темы <script type="math/tex">t</script> в корпусе.</li>
</ul>

<p>Стоит отметить, что согласно пятому свойству, “больше” стоит понимать в абсолютном смысле, ведть большое отрицательно число можно легко превратить в большое положительно, домножив соответствующие вектора <script type="math/tex">u_t, v_t</script> на -1.</p>

<h2 id="section-4">Латентный Семантический Анализ</h2>

<p>На этом с математикой покончено! Осталось собрать элементы мозайки воедино.</p>

<p>Латентный семантический анализ фактически является комбинацией описанных ваше методов. Кратко алгоритм его можно описать следющим образом.</p>

<ol>
  <li>На входе LSA поступает коллекция текстовых документов.</li>
  <li>Текстовые документы переводятся в матрицу частот слов в документах <script type="math/tex">X</script> посредством векторной модели.</li>
  <li>Элементы матрицы <script type="math/tex">X</script> взвешиваются посредством TF-IDF: <script type="math/tex">X_{tfidf} = \mathrm{tfidf}(X)</script>.</li>
  <li>К взвешенной матрице применяется SVD: <script type="math/tex">U_K, S_K, V^\top_K = \mathrm{svd}(X_{tfidf}, K)</script>.</li>
  <li>Полученные тройки <script type="math/tex">u_t, s_t, v_t</script> используются для интерпретаций тем <script type="math/tex">t=1..K</script>.</li>
</ol>

<p>Как видно, среди этапов алгоритма отсутствует стемминг. Тем не менее, эта операция является де-факто стандартом в задачах тематического моделирования и его мы добавили по собственной инициативе в следующем разделе (можно рассмотреть его в качестве шага алгоритма под номером <script type="math/tex">\frac{1}{2}</script>).</p>

<p>На этом с теорией наконец-то покончено, перейдем к практике!</p>

<h1 id="section-5">Часть 2. Практика</h1>

<p>С чего начать? С получения данных, конечно! Нам нужен текст Игры Престолов, желательно всех вышедших книг. Есть различные схемы, в том числе черные и серые, но есть и белые. На правах рекламы, мы воспользовались совершенно белым предложением интернет-магазина litres.ru, где можно приобрести всю серию по <a href="http://www.litres.ru/serii-knig/pesn-lda-i-ognya/elektronnie-knigi/">довольно привлекательной цене</a> — после этого все книги будут доступны в множестве форматов, в том числе и предпочтительным для нас txt.</p>

<p>Когда книги скачены, можно перейти первому этапу — предобработке данных</p>

<h2 id="section-6">Предобработка данных</h2>

<p>Сначала, разберем текст книг по главам и посмотрим на их размер по числу слов.</p>

<p>На примере первой книги “Игры Престолов”:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>Игра_Престолов</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
</pre></td><td class="code"><pre><code class="text"><span class="line">0. Пролог 2925
</span><span class="line">1. Бран 2295
</span><span class="line">2. Кейтилин 1643
</span><span class="line">3. Дейенерис 3284
</span><span class="line">4. Эддард 3068
</span><span class="line">...
</span><span class="line">68. Дейенерис 3273
</span><span class="line">69. Тирион 2738
</span><span class="line">70. Джон 3909
</span><span class="line">71. Кейтилин 3641
</span><span class="line">72. Дейенерис 2738
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>и последней на данный момент книге серии — 2-го тома “Танца с Драконами”:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>Танец_с_Драконами_2</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
</pre></td><td class="code"><pre><code class="text"><span class="line">0. Принц Винтерфелла 4564
</span><span class="line">1. Страж 3891
</span><span class="line">2. Джон 2532
</span><span class="line">3. Тирион 3033
</span><span class="line">4. Переметчивый 3441
</span><span class="line">...
</span><span class="line">31. Укротитель драконов 2584
</span><span class="line">32. Джон 3897
</span><span class="line">33. Десница королевы 4106
</span><span class="line">34. Дейенерис 3775
</span><span class="line">35. Эпилог 4518
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Судя по списку глав все верно, идем дальше. Посмотрим на сам текст — возьмем на вскидку несколько абзацев (точнее, блоков текста, разделенных переносом строки):</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>Пример блоков текста</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
</pre></td><td class="code"><pre><code class="text"><span class="line">Оша поглядела на него.
</span><span class="line">------------------------------
</span><span class="line">– И ты ее ненавидишь?
</span><span class="line">------------------------------
</span><span class="line">– Н-но вы проповедуете материнское милосердие…
</span><span class="line">------------------------------
</span><span class="line">Все хорошо, Грейджой. Слышишь, какая тишь? Тебе бы прыгать от радости. Ты взял Винтерфелл меньше чем с тридцатью людьми – такой подвиг достоин песен. Сейчас он вернется в постель, перевернет Киру на спину и возьмет ее снова, чтобы прогнать призраки. Ее вздохи и смешки рассеют застывшую тишину.
</span><span class="line">------------------------------
</span><span class="line">– Это ваш долг.
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Как видно, здесь есть как довольно осмысленные абзацы, но много и обрывок фраз, вырванных из контекста. Вряд ли, например, фраза “Оша поглядела на него” полезна для определение темы. Эту проблему недостатка контекста мы решим просто: объединим каждые три последующих текстовых блока вместе:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>Пример объединенных блоков текста</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
</pre></td><td class="code"><pre><code class="text"><span class="line">Оша поглядела на него.
</span><span class="line">– Ты просил, и они ответили. Открой уши, прислушайся, сам услышишь.
</span><span class="line">Бран прислушался.
</span><span class="line">------------------------------
</span><span class="line">– И ты ее ненавидишь?
</span><span class="line">– Почти так же сильно, как люблю. Прошу извинить меня, моя королева, – я очень устал.
</span><span class="line">Дени отпустила его, но, когда он уже собрался выйти, она не удержалась и спросила:
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>— уже лучше! Теперь все готово: мы преобразовали исходные тексты в “документы” — объединенные блоки текста. Можно применять LSA.</p>

<h2 id="section-7">Перевод в векторную модель</h2>
<p>Как мы помним, первый этап LSA — перевод документов векторную модель. 
Начнем с разбиения наших документов на слова и их стемминг</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>Разбиение документов на слова</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="kn">import</span> <span class="nn">re</span>
</span><span class="line"><span class="n">non_letter_rgxp</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="s">u&#39;[^а-яА-Я ]&#39;</span><span class="p">)</span>
</span><span class="line">
</span><span class="line"><span class="n">fix_doc</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">doc</span><span class="p">:</span> <span class="n">non_letter_rgxp</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s">&#39; &#39;</span><span class="p">,</span> <span class="n">doc</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>
</span><span class="line">
</span><span class="line"><span class="kn">import</span> <span class="nn">nltk</span>
</span><span class="line"><span class="kn">from</span> <span class="nn">nltk.stem.snowball</span> <span class="kn">import</span> <span class="n">SnowballStemmer</span>
</span><span class="line">
</span><span class="line"><span class="n">stemmer</span> <span class="o">=</span> <span class="n">SnowballStemmer</span><span class="p">(</span><span class="s">&quot;russian&quot;</span><span class="p">)</span>
</span><span class="line">
</span><span class="line"><span class="k">def</span> <span class="nf">stem</span><span class="p">(</span><span class="n">tokens</span><span class="p">):</span>
</span><span class="line">    <span class="k">return</span> <span class="p">(</span><span class="n">stemmer</span><span class="o">.</span><span class="n">stem</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">)</span>
</span><span class="line">
</span><span class="line"><span class="n">docs_tokens</span> <span class="o">=</span> <span class="p">[</span>
</span><span class="line">    <span class="nb">list</span><span class="p">(</span><span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">w</span><span class="p">:</span> <span class="n">w</span><span class="p">,</span> <span class="n">stem</span><span class="p">(</span><span class="n">remove_non_letters</span><span class="p">(</span><span class="n">doc</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s">&#39; &#39;</span><span class="p">))))</span>
</span><span class="line">    <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">docs</span>
</span><span class="line"><span class="p">]</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Теперь, посчитаем частоту слов</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>Подсчет частоты слов</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="kn">import</span> <span class="nn">collections</span>
</span><span class="line">
</span><span class="line"><span class="n">token_frequency_dict</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">defaultdict</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="mi">0</span><span class="p">)</span>
</span><span class="line"><span class="k">for</span> <span class="n">tokens</span> <span class="ow">in</span> <span class="n">docs_tokens</span><span class="p">:</span>
</span><span class="line">    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">:</span>
</span><span class="line">        <span class="n">token_frequency_dict</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Взглянем на наиболее часто встречающиеся слова</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>Самые частые слова</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
</pre></td><td class="code"><pre><code class="text"><span class="line">400392 и
</span><span class="line">271847 он
</span><span class="line">261481 не
</span><span class="line">239817 в
</span><span class="line">187947 на
</span><span class="line">134724 с
</span><span class="line">129038 что
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>.., и на самые редкие</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>Самые редкие слова</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
</pre></td><td class="code"><pre><code class="text"><span class="line">3 линнистер
</span><span class="line">3 близя
</span><span class="line">3 персонаж
</span><span class="line">3 нервнич
</span><span class="line">3 свежеоперен
</span><span class="line">3 прожиг
</span><span class="line">3 долженствова
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Как видно, среди часто встречающихся слов довольно много бессмысленных “коротышек”: “а”, “и”, “не” и т.п. От редких же слов больше вреда, чем пользы: они раздувают словарь слов (а значит и размерность будущей матрицы <script type="math/tex">X</script>, делая вычисления более сложными), а в определении темы вряд ли помогут, так как встречаются в считанном числе документов.</p>

<p>Решено! Отфильтруем самые редкие слова, а так же слова маленькой длинны:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>Фильтрация корпуса по словам</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="n">docs_tokens_filtered</span> <span class="o">=</span> <span class="p">[</span>
</span><span class="line">    <span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">token_frequency_dict</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">5</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">,</span> <span class="n">tokens</span><span class="p">)</span>
</span><span class="line">    <span class="k">for</span> <span class="n">tokens</span> <span class="ow">in</span> <span class="n">docs_tokens</span>
</span><span class="line"><span class="p">]</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Остается перевести наши разбитые на слова и отфильтрованные документы в векторный вид. Следующий блок кода делает именно это.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>Перевод текстовых документов в матрицу частот документ-слов</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
<span class="line-number">22</span>
<span class="line-number">23</span>
<span class="line-number">24</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="kn">import</span> <span class="nn">itertools</span>
</span><span class="line"><span class="kn">import</span> <span class="nn">scipy</span> <span class="kn">as</span> <span class="nn">sp</span>
</span><span class="line">
</span><span class="line"><span class="k">def</span> <span class="nf">flatten</span><span class="p">(</span><span class="n">iterators_iterator</span><span class="p">):</span>
</span><span class="line">    <span class="k">return</span> <span class="n">itertools</span><span class="o">.</span><span class="n">chain</span><span class="o">.</span><span class="n">from_iterable</span><span class="p">(</span><span class="n">iterators_iterator</span><span class="p">)</span>
</span><span class="line">
</span><span class="line"><span class="n">all_tokens</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">flatten</span><span class="p">(</span><span class="n">paragraphs_tokens_filtered</span><span class="p">))</span>
</span><span class="line">
</span><span class="line"><span class="n">id_token_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="n">all_tokens</span><span class="p">))</span>
</span><span class="line"><span class="n">token_id_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(((</span><span class="n">v</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">id_token_dict</span><span class="o">.</span><span class="n">items</span><span class="p">()))</span>
</span><span class="line">
</span><span class="line"><span class="k">def</span> <span class="nf">doc2vec</span><span class="p">(</span><span class="n">doc_tokens</span><span class="p">,</span> <span class="n">token_id_dict</span><span class="p">):</span>
</span><span class="line">    <span class="n">id_cnt_dict</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">Counter</span><span class="p">((</span><span class="n">token_id_dict</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">doc_tokens</span><span class="p">))</span>
</span><span class="line">    <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="n">id_cnt_dict</span><span class="o">.</span><span class="n">items</span><span class="p">())</span>
</span><span class="line">
</span><span class="line"><span class="k">def</span> <span class="nf">docs2csr_matrix</span><span class="p">(</span><span class="n">docs_tokens</span><span class="p">,</span> <span class="n">token_id_dict</span><span class="p">):</span>
</span><span class="line">    <span class="n">docs_vecs</span> <span class="o">=</span> <span class="p">[</span><span class="n">doc2vec</span><span class="p">(</span><span class="n">doc_tokens</span><span class="p">,</span> <span class="n">token_id_dict</span><span class="p">)</span> <span class="k">for</span> <span class="n">doc_tokens</span> <span class="ow">in</span> <span class="n">docs_tokens</span><span class="p">]</span>
</span><span class="line">    <span class="n">data</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">flatten</span><span class="p">((((</span><span class="n">id_cnt</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">id_cnt</span> <span class="ow">in</span> <span class="n">doc_vec</span><span class="p">)</span> <span class="k">for</span> <span class="n">doc_vec</span> <span class="ow">in</span> <span class="n">docs_vecs</span><span class="p">))))</span>
</span><span class="line">    <span class="n">row_ind</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">flatten</span><span class="p">((((</span><span class="n">doc_ind</span> <span class="k">for</span> <span class="n">id_cnt</span> <span class="ow">in</span> <span class="n">doc_vec</span><span class="p">)</span> <span class="k">for</span> <span class="n">doc_ind</span><span class="p">,</span> <span class="n">doc_vec</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">docs_vecs</span><span class="p">)))))</span>
</span><span class="line">    <span class="n">col_ind</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">flatten</span><span class="p">((((</span><span class="n">id_cnt</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">id_cnt</span> <span class="ow">in</span> <span class="n">doc_vec</span><span class="p">)</span> <span class="k">for</span> <span class="n">doc_vec</span> <span class="ow">in</span> <span class="n">docs_vecs</span><span class="p">))))</span>
</span><span class="line">    <span class="k">return</span> <span class="n">sp</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">csr_matrix</span><span class="p">((</span><span class="n">data</span><span class="p">,</span> <span class="p">(</span><span class="n">row_ind</span><span class="p">,</span> <span class="n">col_ind</span><span class="p">)),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
</span><span class="line">
</span><span class="line">
</span><span class="line"><span class="n">X</span> <span class="o">=</span> <span class="n">docs2csr_matrix</span><span class="p">(</span><span class="n">docs_tokens_filtered</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Ура, мы в векторе! Получилась матрица 48977 на 27673, идем дальше.</p>

<h2 id="tfidf">TFIDF</h2>
<p>Следующим по списку стоит TFIDF. Воспользуемся собственной реализацией.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>TFIDF</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="k">def</span> <span class="nf">tfidf</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
</span><span class="line">    <span class="n">idf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">((</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="mf">1.</span> <span class="o">/</span> <span class="p">((</span><span class="n">X</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1.</span>
</span><span class="line">    <span class="n">idf</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">spdiags</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">idf</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span> <span class="n">diags</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">m</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">n</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</span><span class="line">    <span class="k">return</span> <span class="n">X</span> <span class="o">*</span> <span class="n">idf</span>
</span><span class="line">
</span><span class="line"><span class="n">X_tfidf</span> <span class="o">=</span> <span class="n">tfidf</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h2 id="svd">Применение SVD</h2>
<p>На этот раз свой велосипед писать не будем, воспользуемся готовой реализацией для разряженных матриц (а нас как-раз такая) из пакета <a href="http://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.svds.html">scipy</a>.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>SVD</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="n">U</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">VT</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svds</span><span class="p">(</span><span class="n">X_tfidf</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">40</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Вот и все, готово! Давайте посмотрим, какие темы нашел LSA.</p>

<h1 id="section-8">Часть 3. Результаты</h1>

<p>Взглянем на сингулярные числа <script type="math/tex">s_t</script> соответствующую вкладу каждой тему в коллекцию</p>

<p><img src="/images/2015-09_TopicModelling_GameOfThrones/GameOfThrones_singular_values_histogram.png" width="768" height="576" /></p>

<p>Первое собственное число всех стоит одинокой башней. Неужели есть какая-та настолько “выдающаяся” тема?<br />
Как мы говорили выше, элементы вектора <script type="math/tex">v_t</script> соответствуют вкладу соответствующих слов в тему <script type="math/tex">t</script>. Посмотрим же на самые большие по модулю элементы вектора <script type="math/tex">v_0</script>. А для наглядности  рядом с каждым значением припишем соответствующее слово, представив их в формате “вес”*“слово”.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>Первый правый собственный вектор</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="text"><span class="line">Тема №1: +0.268*что +0.224*как +0.196*был +0.173*сво +0.147*лорд +0.145*так +0.131*все +0.125*когд +0.115*сир +0.102*сказа +0.099*чтоб +0.097*есл +0.095*котор +0.095*сам +0.094*друг +0.093*джон +0.089*корол +0.089*рук +0.089*тольк +0.086*больш
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Удивительно, что все элементы одного знака (мы все-все проверили). Получается такая тема, которой соответствуют все слова без исключения. Но если подумать, то ничего удивительного в этом нет. Вспомним базовую статистику. Если взять множество чисел, какое число будет минимизировать сумму квадратов расстояний от них? Правильно — их среднее. И здесь та же история: фактически, вектор <script type="math/tex">v_0</script> — это среднее по строкам матрицы <script type="math/tex">X_{tfidf}</script>, то есть вектор средних весов слов в нашем корпусе. Исходя из этого, первая собственная тройка с точки зрения определения темы нам мало полезна, так что отбросим ее и вновь взглянем на график собственных чисел.</p>

<p><img src="/images/2015-09_TopicModelling_GameOfThrones/GameOfThrones_singular_values_histogram_without_1st.png" width="768" height="576" /></p>

<p>Теперь сильно выделяющихся тем нет. Далее пойдем по порядку, рассмотрим слова, образующие темы со 2-й по 7-ю.</p>

<h3 id="section-9">Тема 2. “Власть?”</h3>

<p><img src="/images/2015-09_TopicModelling_GameOfThrones/RobertBaratheon_in_Winterfell.jpg" width="768" height="576" title="Старки встречают Роберта Баратеона" /></p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>Наиболее важные слова 2-ой темы</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="text"><span class="line">Тема №2: +0.27*лорд -0.23*джон +0.15*корол +0.15*ваш -0.15*стен +0.15*сир +0.14*что -0.13*черн +0.13*мне +0.12*мен -0.12*бран -0.11*сэм +0.11*есл -0.10*был -0.10*дерев +0.10*роберт -0.09*под +0.09*теб -0.08*ног -0.08*ден
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Похоже, что Джон — самый “важный” герой серии, во всяком случае с точки зрения LSA :). 
Вторую тему можно интерпретировать двумя способами. Во-первых, эта тема посвящена властьимущим: лордам, королям, сирам, — об этом говорят и местоимения “ваш”, “мне”, “мен”. Если 
взглянуть на <a href="https://gist.github.com/Obus/e7cf9223fa7bdc4cda5f">самые близкие к этой теме документы</a> (близость к документа к теме определяется на основе матрицы <script type="math/tex">US</script>), то можно заметить, что ближе всего к этой теме относятся документы, в которой речь идет о лордах: Ренли и Станисе Баратеонах, лорде Тайвине, лорде-главнокомандующем, об общем лорде-отце, о бесчисленных лордах меньшего размаха, или же  чем-нибудь королевском, например, о короле Роберте, короле Станнисе, королевской деснице, королевской гвардии, и даже о Королевском лесе. Во-вторых, если рассмотреть эту тему “наоборот”, домножив вектора <script type="math/tex">u_2</script> и <script type="math/tex">v_2</script> на -1 (пользуемся свойством SVD номер 5), то ее можно интерпретировать как тему анархии. Так среди соответствующих ей <a href="https://gist.github.com/Obus/ead759846f8a69d51854">документов</a> можно встретить множество относящихся к проделкам Арьи Старк и похождениям Джона Сноу с одичалыми.</p>

<h3 id="section-10">Тема 3. “Джон Сноу и его друзья?”</h3>

<p><img src="/images/2015-09_TopicModelling_GameOfThrones/JonSnow_NW_trainee.jpg" width="768" height="576" title="Джон Сноу, тренировка в Ночном Дозоре" /></p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>Наиболее важные слова 3-ей темы</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="text"><span class="line">Тема №3: +0.38*джон -0.32*сир +0.23*сэм +0.22*что +0.15*теб -0.15*ден -0.15*рыцар +0.15*бран -0.13*тирион -0.12*золот +0.11*мне -0.10*джейм +0.09*так -0.09*меч +0.09*есл -0.09*красн +0.09*одичал +0.08*мен +0.08*дозор +0.08*мейстер
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Третья тема вполне очевидная: она посвящена Джону Сноу, по большей части эпизодам с участием Сэма Тарли, в чем можно убедиться взглянув на <a href="https://gist.github.com/Obus/53fea013e8a368fd94cd">ее документы</a>.
Большой отрицательный вес у слова “сир” легко объясним: к кому в ночном дозоре можно так обратиться?</p>

<p>Взглянем на следующую тему</p>

<h3 id="section-11">Тема 4. “Северные Лорды”? или “Матерь Драконов”</h3>

<p><img src="/images/2015-09_TopicModelling_GameOfThrones/RobbSark_Whispering_Wood_Crop2.png" width="384" height="256" title="Северные Лорды" />
<img src="/images/2015-09_TopicModelling_GameOfThrones/MotherOfDragons.jpg" width="384" height="256" title="Матерь Драконов" /></p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>Наиболее важные слова 4-ой темы</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="text"><span class="line">Тема №4: +0.41*лорд -0.31*ден +0.30*джон -0.20*что +0.18*сир -0.15*дракон -0.14*теб -0.12*так +0.12*робб +0.11*корол -0.11*кхал -0.11*мне -0.10*мен -0.10*дрог +0.10*кейтилин -0.10*как +0.09*стен +0.09*старк +0.08*меч +0.07*станнис
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>— вновь о Джоне! На этот раз, в отличие от второй темы, “джон” не противопоставляется “лорду”. Наоборот, <a href="https://gist.github.com/Obus/d1bf933cf83323bab21a">документы относящиеся к этой теме</a> довольно часто описывают либо эпизоды из жизни лордов: лорда главнокомандующего, Робба Старка в окружении северных лордов и прочих. Примечательно, что Дейнерис (“ден”) в этой теме находится в “противоположном углу” этой темы — лордов в ее окружении совсем немного. <a href="https://gist.github.com/Obus/b137a78c9b876759f3bc">Документы противоположного угла</a> целиком посвящены Дейнерис: здесь и “дракон”ы и “кхал” и “дрог”о. Особенно превалирует тема драконов.</p>

<p>На очереди 5-я тема</p>

<h3 id="section-12">Тема 5. “Винтерфелл” или “Джон и Сэм”</h3>

<p><img src="/images/2015-09_TopicModelling_GameOfThrones/game-of-thrones-starks-in-winterfell.png" width="768" height="576" title="Старки в Винтерфелле" /></p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>Наиболее важные слова 5-ой темы</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="text"><span class="line">Тема №5: -0.55*бран -0.31*ходор +0.28*джон +0.19*сэм -0.16*робб -0.15*санс -0.13*был +0.10*станнис +0.10*давос -0.10*кейтилин -0.09*лет -0.09*винтерфелл +0.08*дракон -0.08*что +0.08*корабл +0.08*одичал -0.08*рикон -0.08*волк +0.07*черн -0.07*лювин
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Эту тему так же можно интерпретировать двояко. Один из полюсов - это полюс Винтерфелла: “бран”, “ходор”, “робб”, “санс”, “кейтилин” и другие — это указывает на события происходящие в замке еще до начала войны. С другой стороны, нельзя не отметить, что пара “бран” и “ходор” превалируют: если вглянуть на <a href="https://gist.github.com/Obus/ff4f142a39ea5d18f2f1">документы этого полюса</a>, то можно убедиться что среди них довольно много относящихся к путешествию Брана и Ходора за стену.  На другом полюсе это еще одна тема “посвященная” Сэму Тарли и Джону Сноу. От третьей темы ее отличает отрицание всего что связано с Винтерфеллом: слов “бран”, “робб”, “санс”, “кейтилин”, “винтерфелл” и др., при этом ориентированность на событиям после победы над одичалыми: на то указывают слова “станнис” и “давос”. Документы этого полюса доступны по <a href="https://gist.github.com/Obus/6863dd57ccd7ba245017">ссылке</a>.</p>

<h3 id="section-13">Тема 6. “Боевая”</h3>

<p><img src="/images/2015-09_TopicModelling_GameOfThrones/Aria_vs_Sirio.jpeg" width="768" height="576" title="Учебный поединок Арьи Старк с Сирио Форелем" /></p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>Наиболее важные слова 6-ой темы</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="text"><span class="line">Тема №6: -0.25*тирион -0.23*сир -0.18*джон +0.18*лорд -0.18*рук -0.16*меч -0.16*санс +0.15*ден +0.15*дракон +0.15*давос -0.15*теб -0.14*джейм +0.14*бран +0.12*мор +0.12*корол -0.12*сэм +0.11*корабл -0.11*удар +0.10*станнис +0.09*бог
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>В этой теме наиболее интересна ее “обратная сторона” (полученная умножением на единицу). Здесь превалируют такие слова, как “тирион”, “сир”, “джон”, “рук”, “меч” и т.д. Если взглянуть на соответствующие ей <a href="https://gist.github.com/Obus/0fab1293f682d800e9e2">документы</a>, то окажется что эта тема боя, поединок: в нее попадает сражение от лица Тириона на Черноводной, битва Сэма с мертвым Малышом Паулом, поединок между Бронном и сиром Вардисом Игеном в Орлином Гнезде, бой Джона Сноу с Костяным Лордом и многие другие. Таким образом, ключевыми здесь оказываются слова “рук”, “меч”, “удар” и т.п., а веса отдельных персонажей лишь указывают на их участие в сражениях.</p>

<p>И наконец, 7-я тема</p>

<h3 id="section-14">Тема 7. “Битва при Черноводной” или “Джон Сноу и Дейнерис Таргириен?”</h3>

<p><img src="/images/2015-09_TopicModelling_GameOfThrones/TIrion_Blackwater_Angry.jpg" width="768" height="576" title="Тирион в битве при Черноводной" /></p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>Наиболее важные слова 7-ой темы</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="text"><span class="line">Тема №7: -0.35*ден -0.32*джон +0.29*тирион -0.25*сир +0.17*давос -0.17*кхал -0.15*дрог +0.15*как +0.13*корабл -0.10*ваш -0.10*брат +0.10*лорд -0.10*корол -0.10*бран +0.10*сэм -0.09*джор -0.09*нед -0.09*дракон +0.09*вод -0.08*был
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>С одной стороны, эта тема — еще одна тема касающаяся сражения, но теперь вполне конкретного: битвы при Черноводной. Об этом можно догадаться взглянув на основны слова: “тирион” (со стороны обороняющихся), “давос” (со стороны нападавших), “корабль” и “вод”. Совсем очевидно это становиться, если посмотреть на <a href="https://gist.github.com/Obus/f3b80aa271a46cafb044">соответствующие этой “стороне” темы документы</a> — все они относятся к битве у Черноводной.</p>

<p>Если посмотреть с другой стороны, то это довольно таки загадочная тема, которую попалам делят Джон Сноу и Дейнерис Таргариен: с одной стороны здесь “ден”, “кхал” и “дрого”, а с другой “джон”, “бран” и “нед”. Если взглянуть на <a href="https://gist.github.com/Obus/c615dc92dc99c350ec1c">соответствующие документы</a>, то можно заметить, что практически все они содержат слово “сир”: что со стороны Дейнерис, что со стороны Джона, а так же часто общим является слово “брат”: на севере братьев не счесть, а на юге это брат Дейнерис — пока еще живой Визерис.</p>

<h1 id="section-15">Заключение</h1>

<p>Если вас заинтересовал тема тем (прошу прощения за дурной каламбур) в Игре Престолов, то по <a href="https://gist.github.com/Obus/a6b40e31e9a9535eb757">ссылке</a> доступны по 20 наиболее важных тем для первых 42 тем. Если же хочется поиграться с темами самостоятельно, то в качестве отправных точек могу посоветовать следующее</p>

<ol>
  <li><a href="не готово еще">IPython Notebook</a> с кодом, используемым в этой статье, и полученными результатами.</li>
  <li>Python пакет <a href="https://radimrehurek.com/gensim/">gensim</a>, содержащий как вспомогательный инструменты для создания корпуса, реализацию LSA, так и реализации гораздо более сложных, но и интересных методов тематического моделирования</li>
  <li><a href="http://www.machinelearning.ru/wiki/index.php?title=%D0%A2%D0%B5%D0%BC%D0%B0%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%BE%D0%B5_%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5">Статья</a> на machinelearning.ru</li>
</ol>

<p>Надеюсь, что было интересно :)</p>

<p>До встречи!</p>
</div>


  <footer>
    <p class="meta">
      
  

<span class="byline author vcard">Опубликовал <span class="fn">Alexander Senov</span></span>

      




<time class='entry-date' datetime='2015-09-13T14:54:20+03:00'><span class='date'>13/09/2015</span> <span class='time'>14:54</span></time>
      


    </p>
    
      <div class="sharing">
  
  <a href="//twitter.com/share" class="twitter-share-button" data-url="http://datadeep.ru/blog/2015/09/13/zim-blizk/" data-via="" data-counturl="http://datadeep.ru/blog/2015/09/13/zim-blizk/" >Tweet</a>
  
  
  <div class="g-plusone" data-size="medium"></div>
  
  
    <div class="fb-like" data-send="true" data-width="450" data-show-faces="false"></div>
  
  
    <div id="vk_like"></div>
    <script type="text/javascript">
    window.onload = function () {
        VK.init({apiId: 4631132, onlyWidgets: true});
        VK.Widgets.Like("vk_like", {type: "mini"});
    }
    </script>
  
</div>

    
    <p class="meta">
      
      
    </p>
  </footer>
</article>

</div>

<aside class="sidebar">
  
    <section>
  <h1>Недавние Посты</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2015/09/13/zim-blizk/">Ищем темы в Игре Престолов</a>
      </li>
    
  </ul>
</section>




<section>
  <h1>Категории</h1>
    <ul id="category-list"></ul>
</section>

  
</aside>


    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2015 - Команда datadeep.ru -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  



<div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) {return;}
  js = d.createElement(s); js.id = id; js.async = true;
  js.src = "//connect.facebook.net/en_US/all.js#appId=212934732101925&xfbml=1";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>



  <script type="text/javascript">
    (function() {
      var script = document.createElement('script'); script.type = 'text/javascript'; script.async = true;
      script.src = 'https://apis.google.com/js/plusone.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(script, s);
    })();
  </script>



  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = '//platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>




  <script type="text/javascript" src="//vk.com/js/api/openapi.js?75"></script>




</body>
</html>

<!-- mathjax config similar to math.stackexchange -->
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  jax: ["input/TeX", "output/HTML-CSS"],
  tex2jax: {
    inlineMath: [ ['$', '$'] ],
    displayMath: [ ['$$', '$$']],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  messageStyle: "none",
  "HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] }
});
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script>

